{"cells":[{"cell_type":"code","source":["import os, sys\nsys.path.append(os.getcwd())\n\nfrom random import randint\n\nimport time\nimport functools\nimport math\n\nimport numpy as np\nimport tensorflow as tf\n\nimport tflib as lib\nimport tflib.ops.linear\nimport tflib.ops.conv2d\nimport tflib.ops.batchnorm\nimport tflib.ops.deconv2d\nimport tflib.save_images\nimport tflib.wikiartGenre\nimport tflib.ops.layernorm\nimport tflib.plot\n\n\nMODE = 'acwgan' # dcgan, wgan, wgan-gp, lsgan\nDIM = 64 # Model dimensionality\nCRITIC_ITERS = 5 # How many iterations to train the critic for\nN_GPUS = 1 # Number of GPUs\nBATCH_SIZE = 84 # Batch size. Must be a multiple of CLASSES and N_GPUS\nITERS = 200000 # How many iterations to train for\nLAMBDA = 10 # Gradient penalty lambda hyperparameter\nOUTPUT_DIM = 64*64*3 # Number of pixels in each iamge\nCLASSES = 14 #Number of classes, for genres probably 14\nPREITERATIONS = 2000 #Number of preiteration training cycles to run\nlib.print_model_settings(locals().copy())\n\ndef GeneratorAndDiscriminator():\n    return kACGANGenerator, kACGANDiscriminator\n\n\nDEVICES = ['/gpu:{}'.format(i) for i in range(N_GPUS)]\n\ndef LeakyReLU(x, alpha=0.2):\n    return tf.maximum(alpha*x, x)\n\ndef ReLULayer(name, n_in, n_out, inputs):\n    output = lib.ops.linear.Linear(name+'.Linear', n_in, n_out, inputs, initialization='he')\n    return tf.nn.relu(output)\n\ndef LeakyReLULayer(name, n_in, n_out, inputs):\n    output = lib.ops.linear.Linear(name+'.Linear', n_in, n_out, inputs, initialization='he')\n    return LeakyReLU(output)\n\ndef Batchnorm(name, axes, inputs):\n    \n    if ('Discriminator' in name) and (MODE == 'wgan-gp' or MODE == 'acwgan'):\n        if axes != [0,2,3]:\n            raise Exception('Layernorm over non-standard axes is unsupported')\n        return lib.ops.layernorm.Layernorm(name,[1,2,3],inputs)\n    else:\n        return lib.ops.batchnorm.Batchnorm(name,axes,inputs,fused=True)\n\ndef pixcnn_gated_nonlinearity(name, output_dim, a, b, c=None, d=None):\n    if c is not None and d is not None:\n        a = a + c\n        b = b + d\n        \n    result = tf.sigmoid(a) * tf.tanh(b)\n    return result\n\ndef SubpixelConv2D(*args, **kwargs):\n    kwargs['output_dim'] = 4*kwargs['output_dim']\n    output = lib.ops.conv2d.Conv2D(*args, **kwargs)\n    output = tf.transpose(output, [0,2,3,1])\n    output = tf.depth_to_space(output, 2)\n    output = tf.transpose(output, [0,3,1,2])\n    return output\n\ndef ResidualBlock(name, input_dim, output_dim, filter_size, inputs, resample=None, he_init=True):\n    \"\"\"\n    resample: None, 'down', or 'up'\n    \"\"\"\n    if resample=='down':\n        conv_shortcut = functools.partial(lib.ops.conv2d.Conv2D, stride=2)\n        conv_1        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim//2)\n        conv_1b       = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim//2, output_dim=output_dim//2, stride=2)\n        conv_2        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=output_dim//2, output_dim=output_dim)\n    elif resample=='up':\n        conv_shortcut = SubpixelConv2D\n        conv_1        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim//2)\n        conv_1b       = functools.partial(lib.ops.deconv2d.Deconv2D, input_dim=input_dim//2, output_dim=output_dim//2)\n        conv_2        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=output_dim//2, output_dim=output_dim)\n    elif resample==None:\n        conv_shortcut = lib.ops.conv2d.Conv2D\n        conv_1        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim,  output_dim=input_dim//2)\n        conv_1b       = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim//2,  output_dim=output_dim//2)\n        conv_2        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim//2, output_dim=output_dim)\n\n    else:\n        raise Exception('invalid resample value')\n\n    if output_dim==input_dim and resample==None:\n        shortcut = inputs # Identity skip-connection\n    else:\n        shortcut = conv_shortcut(name+'.Shortcut', input_dim=input_dim, output_dim=output_dim, filter_size=1,\n                                 he_init=False, biases=True, inputs=inputs)\n\n    output = inputs\n    output = tf.nn.relu(output)\n    output = conv_1(name+'.Conv1', filter_size=1, inputs=output, he_init=he_init, weightnorm=False)\n    output = tf.nn.relu(output)\n    output = conv_1b(name+'.Conv1B', filter_size=filter_size, inputs=output, he_init=he_init, weightnorm=False)\n    output = tf.nn.relu(output)\n    output = conv_2(name+'.Conv2', filter_size=1, inputs=output, he_init=he_init, weightnorm=False, biases=False)\n    output = Batchnorm(name+'.BN', [0,2,3], output)\n\n    return shortcut + (0.3*output)\n\n# ! Generators\n\ndef kACGANGenerator(n_samples, numClasses, labels, noise=None, dim=DIM, bn=True, nonlinearity=tf.nn.relu, condition=None):\n    lib.ops.conv2d.set_weights_stdev(0.02)\n    lib.ops.deconv2d.set_weights_stdev(0.02)\n    lib.ops.linear.set_weights_stdev(0.02)\n    if noise is None:\n        noise = tf.random_normal([n_samples, 128])\n\n    labels = tf.cast(labels, tf.float32)        \n    noise = tf.concat([noise, labels], 1)\n\n    output = lib.ops.linear.Linear('Generator.Input', 128+numClasses, 8*4*4*dim*2, noise) #probs need to recalculate dimensions\n    output = tf.reshape(output, [-1, 8*dim*2, 4, 4])\n    if bn:\n        output = Batchnorm('Generator.BN1', [0,2,3], output)\n    condition = lib.ops.linear.Linear('Generator.cond1', numClasses, 8*4*4*dim*2, labels,biases=False)\n    condition = tf.reshape(condition, [-1, 8*dim*2, 4, 4])\n    output = pixcnn_gated_nonlinearity('Generator.nl1', 8*dim, output[:,::2], output[:,1::2], condition[:,::2], condition[:,1::2])\n\n\n    output = lib.ops.deconv2d.Deconv2D('Generator.2', 8*dim, 4*dim*2, 5, output)\n    if bn:\n        output = Batchnorm('Generator.BN2', [0,2,3], output)\n    condition = lib.ops.linear.Linear('Generator.cond2', numClasses, 4*8*8*dim*2, labels)\n    condition = tf.reshape(condition, [-1, 4*dim*2, 8, 8])\n    output = pixcnn_gated_nonlinearity('Generator.nl2', 4*dim,output[:,::2], output[:,1::2], condition[:,::2], condition[:,1::2])\n    \n    output = lib.ops.deconv2d.Deconv2D('Generator.3', 4*dim, 2*dim*2, 5, output)\n    if bn:\n        output = Batchnorm('Generator.BN3', [0,2,3], output)\n    condition = lib.ops.linear.Linear('Generator.cond3', numClasses, 2*16*16*dim*2, labels)\n    condition = tf.reshape(condition, [-1, 2*dim*2, 16, 16])\n    output = pixcnn_gated_nonlinearity('Generator.nl3', 2*dim,output[:,::2], output[:,1::2], condition[:,::2], condition[:,1::2])\n    \n    output = lib.ops.deconv2d.Deconv2D('Generator.4', 2*dim, dim*2, 5, output)\n    if bn:\n        output = Batchnorm('Generator.BN4', [0,2,3], output)\n    condition = lib.ops.linear.Linear('Generator.cond4', numClasses, 32*32*dim*2, labels)\n    condition = tf.reshape(condition, [-1, dim*2, 32, 32])\n    output = pixcnn_gated_nonlinearity('Generator.nl4', dim, output[:,::2], output[:,1::2], condition[:,::2], condition[:,1::2])\n\n    output = lib.ops.deconv2d.Deconv2D('Generator.5', dim, 3, 5, output)\n\n    output = tf.tanh(output)\n    \n    lib.ops.conv2d.unset_weights_stdev()\n    lib.ops.deconv2d.unset_weights_stdev()\n    lib.ops.linear.unset_weights_stdev()\n\n    return tf.reshape(output, [-1, OUTPUT_DIM]), labels\n\ndef kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n    output = tf.reshape(inputs, [-1, 3, 64, 64])\n\n    lib.ops.conv2d.set_weights_stdev(0.02)\n    lib.ops.deconv2d.set_weights_stdev(0.02)\n    lib.ops.linear.set_weights_stdev(0.02)\n    \n    output = lib.ops.conv2d.Conv2D('Discriminator.1', 3, dim, 5, output, stride=2)\n    output = nonlinearity(output)\n\n    output = lib.ops.conv2d.Conv2D('Discriminator.2', dim, 2*dim, 5, output, stride=2)\n    if bn:\n        output = Batchnorm('Discriminator.BN2', [0,2,3], output)\n    output = nonlinearity(output)\n\n    output = lib.ops.conv2d.Conv2D('Discriminator.3', 2*dim, 4*dim, 5, output, stride=2)\n    if bn:\n        output = Batchnorm('Discriminator.BN3', [0,2,3], output)\n    output = nonlinearity(output)\n\n    \n    output = lib.ops.conv2d.Conv2D('Discriminator.4', 4*dim, 8*dim, 5, output, stride=2)\n    if bn:\n        output = Batchnorm('Discriminator.BN4', [0,2,3], output)\n    output = nonlinearity(output)\n    finalLayer = tf.reshape(output, [-1, 4*4*8*dim])\n\n    sourceOutput = lib.ops.linear.Linear('Discriminator.sourceOutput', 4*4*8*dim, 1, finalLayer)\n    \n    classOutput = lib.ops.linear.Linear('Discriminator.classOutput', 4*4*8*dim, numClasses, finalLayer)\n\n    lib.ops.conv2d.unset_weights_stdev()\n    lib.ops.deconv2d.unset_weights_stdev()\n    lib.ops.linear.unset_weights_stdev()\n\n\n\n    return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))\n\n                                \ndef genRandomLabels(n_samples, numClasses,condition=None):\n    labels = np.zeros([BATCH_SIZE,CLASSES], dtype=np.float32)\n    for i in range(n_samples):\n        if condition is not None:\n            labelNum = condition\n        else:\n            labelNum = randint(0, numClasses-1)\n        labels[i, labelNum] = 1\n    return labels\n\nGenerator, Discriminator = GeneratorAndDiscriminator()\n            \nwith tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as session:\n\n    all_real_data_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, 3, 64, 64])\n    all_real_label_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE,CLASSES])\n    \n    generated_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE,CLASSES])\n    sample_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE,CLASSES])\n    \n    if tf.__version__.startswith('1.'):\n        split_real_data_conv = tf.split(all_real_data_conv, len(DEVICES))\n        split_real_label_conv = tf.split(all_real_label_conv, len(DEVICES))\n        split_generated_labels_conv = tf.split(generated_labels_conv, len(DEVICES))\n        split_sample_labels_conv = tf.split(sample_labels_conv, len(DEVICES))\n    else:\n        split_real_data_conv = tf.split(0, len(DEVICES), all_real_data_conv)\n        split_real_data_label = tf.split(0, len(DEVICES), all_real_data_conv)\n        split_generated_labels = tf.split(0, len(DEVICES), generated_labels_conv)\n        split_sample_labels = tf.split(0, len(DEVICES), sample_labels_conv)\n\n    gen_costs, disc_costs = [],[]\n\n    for device_index, (device, real_data_conv, real_label_conv) in enumerate(zip(DEVICES, split_real_data_conv, split_real_label_conv)):\n        with tf.device(device):\n            \n            real_data = tf.reshape(2*((tf.cast(real_data_conv, tf.float32)/255.)-.5), [BATCH_SIZE//len(DEVICES), OUTPUT_DIM])\n            real_labels = tf.reshape(real_label_conv, [BATCH_SIZE//len(DEVICES), CLASSES])\n\n            generated_labels = tf.reshape(split_generated_labels_conv, [BATCH_SIZE//len(DEVICES), CLASSES])\n            sample_labels = tf.reshape(split_sample_labels_conv, [BATCH_SIZE//len(DEVICES), CLASSES])\n                        \n            fake_data, fake_labels= Generator(BATCH_SIZE//len(DEVICES), CLASSES, generated_labels)\n            \n            #set up discrimnator results\n            \n            disc_fake,disc_fake_class = Discriminator(fake_data, CLASSES)\n            disc_real,disc_real_class = Discriminator(real_data, CLASSES)\n                \n            prediction = tf.argmax(disc_fake_class, 1)\n            correct_answer = tf.argmax(fake_labels, 1)\n            equality = tf.equal(prediction, correct_answer)\n            genAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n            \n            prediction = tf.argmax(disc_real_class, 1)\n            correct_answer = tf.argmax(real_labels, 1)\n            equality = tf.equal(prediction, correct_answer)\n            realAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n\n            gen_cost = -tf.reduce_mean(disc_fake)\n            disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n\n            gen_cost_test = -tf.reduce_mean(disc_fake)\n            disc_cost_test = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n                                                                                     \n            generated_class_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=disc_fake_class,\n                                                                                              labels=fake_labels))\n            \n\n            real_class_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=disc_real_class,\n                                                                                              labels=real_labels))\n            gen_cost += generated_class_cost\n            disc_cost += real_class_cost\n                \n            alpha = tf.random_uniform(\n                shape=[BATCH_SIZE//len(DEVICES),1], \n                minval=0.,\n                maxval=1.\n            )\n            differences = fake_data - real_data\n            interpolates = real_data + (alpha*differences)\n            gradients = tf.gradients(Discriminator(interpolates, CLASSES)[0], [interpolates])[0]\n            slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n            gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n            disc_cost += LAMBDA*gradient_penalty\n            \n            real_class_cost_gradient = real_class_cost*50 + LAMBDA*gradient_penalty\n            \n\n            gen_costs.append(gen_cost)\n            disc_costs.append(disc_cost)\n\n    gen_cost = tf.add_n(gen_costs) / len(DEVICES)\n    disc_cost = tf.add_n(disc_costs) / len(DEVICES)\n            \n    gen_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9).minimize(gen_cost,\n                                                                                             var_list=lib.params_with_name('Generator'),\n                                                                                             colocate_gradients_with_ops=True)\n    disc_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9).minimize(disc_cost,\n                                                                                              var_list=lib.params_with_name('Discriminator.'),\n                                                                                              colocate_gradients_with_ops=True)\n    class_train_op =  tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9).minimize(real_class_cost_gradient,\n                                                                                                var_list=lib.params_with_name('Discriminator.'),\n                                                                                                colocate_gradients_with_ops=True)\n    # For generating samples\n    \n    fixed_noise = tf.constant(np.random.normal(size=(BATCH_SIZE, 128)).astype('float32'))\n    all_fixed_noise_samples = []\n    for device_index, device in enumerate(DEVICES):\n        n_samples = BATCH_SIZE // len(DEVICES)\n        all_fixed_noise_samples.append(Generator(n_samples, CLASSES, sample_labels,noise=fixed_noise[device_index*n_samples:(device_index+1)*n_samples])[0])\n        if tf.__version__.startswith('1.'):\n            all_fixed_noise_samples = tf.concat(all_fixed_noise_samples, axis=0)\n        else:\n            all_fixed_noise_samples = tf.concat(0, all_fixed_noise_samples)\n    \n    \n    def generate_image(iteration):\n        for i in range(CLASSES):\n            curLabel= genRandomLabels(BATCH_SIZE,CLASSES,condition=i)\n            samples = session.run(all_fixed_noise_samples, feed_dict={sample_labels: curLabel})\n            samples = ((samples+1.)*(255.99/2)).astype('int32')\n            lib.save_images.save_images(samples.reshape((BATCH_SIZE, 3, 64, 64)), 'generated/samples_{}_{}.png'.format(str(i), iteration))\n    \n    \n    \n    # Dataset iterator\n    train_gen, dev_gen = lib.wikiartGenre.load(BATCH_SIZE)\n\n    def softmax_cross_entropy(logit, y):\n        return -tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y))\n    \n    def inf_train_gen():\n        while True:\n            for (images,labels) in train_gen():\n                yield images,labels\n\n\n    _sample_labels = genRandomLabels(BATCH_SIZE, CLASSES)\n    # Save a batch of ground-truth samples\n    _x,_y = next(train_gen())\n    _x_r = session.run(real_data, feed_dict={all_real_data_conv: _x})\n    _x_r = ((_x_r+1.)*(255.99/2)).astype('int32')\n    lib.save_images.save_images(_x_r.reshape((BATCH_SIZE, 3, 64, 64)), 'generated/samples_groundtruth.png')\n\n\n\n    session.run(tf.initialize_all_variables(), feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE,CLASSES)})\n    gen = train_gen()\n    \n    for iterp in range(PREITERATIONS):\n        _data, _labels = next(gen)\n        _ , accuracy = session.run([disc_train_op, realAccuracy],feed_dict = {all_real_data_conv: _data, all_real_label_conv: _labels, generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES)})\n        if iterp % 100 == 99:\n            print('pretraining accuracy: ' + str(accuracy))\n    \n            \n    for iteration in range(ITERS):\n        start_time = time.time()\n        # Train generator\n        if iteration > 0:\n            _ = session.run(gen_train_op, feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE,CLASSES)})\n        # Train critic\n        disc_iters = CRITIC_ITERS\n        for i in range(disc_iters):\n            _data, _labels = next(gen)\n            _disc_cost, _disc_cost_test, class_cost_test, gen_class_cost, _gen_cost_test, _genAccuracy, _realAccuracy, _ = session.run([disc_cost, disc_cost_test, real_class_cost, generated_class_cost, gen_cost_test, genAccuracy, realAccuracy, disc_train_op], feed_dict={all_real_data_conv: _data, all_real_label_conv: _labels, generated_labels_conv: genRandomLabels(BATCH_SIZE,CLASSES)})\n         \n        lib.plot.plot('train disc cost', _disc_cost)   \n        lib.plot.plot('time', time.time() - start_time)\n        lib.plot.plot('wgan train disc cost', _disc_cost_test)\n        lib.plot.plot('train class cost', class_cost_test)\n        lib.plot.plot('generated class cost', gen_class_cost)\n        lib.plot.plot('gen cost cost', _gen_cost_test)\n        lib.plot.plot('gen accuracy', _genAccuracy)\n        lib.plot.plot('real accuracy', _realAccuracy)        \n        \n        if (iteration % 100 == 99 and iteration<1000) or iteration % 1000 == 999 :\n            t = time.time()\n            dev_disc_costs = []\n            images, labels = next(dev_gen())\n            _dev_disc_cost, _dev_disc_cost_test, _class_cost_test, _gen_class_cost, _dev_gen_cost_test, _dev_genAccuracy, _dev_realAccuracy = session.run([disc_cost, disc_cost_test, real_class_cost, generated_class_cost, gen_cost_test, genAccuracy, realAccuracy], feed_dict={all_real_data_conv: images, all_real_label_conv: labels, generated_labels_conv: genRandomLabels(BATCH_SIZE,CLASSES)})\n            dev_disc_costs.append(_dev_disc_cost)\n            lib.plot.plot('dev disc cost', np.mean(dev_disc_costs))\n            lib.plot.plot('wgan dev disc cost', _dev_disc_cost_test)\n            lib.plot.plot('dev class cost', _class_cost_test)\n            lib.plot.plot('dev generated class cost', _gen_class_cost)\n            lib.plot.plot('dev gen  cost', _dev_gen_cost_test)\n            lib.plot.plot('dev gen accuracy', _dev_genAccuracy)\n            lib.plot.plot('dev real accuracy', _dev_realAccuracy)        \n\n\n        if iteration % 1000 == 999:\n            generate_image(iteration)\n            #Can add generate_good_images method in here if desired\n            \n        if (iteration < 10) or (iteration % 100 == 99):\n            lib.plot.flush()\n\n        lib.plot.tick()"],"metadata":{},"outputs":[],"execution_count":1}],"metadata":{"name":"GANGogh","notebookId":128113317169839},"nbformat":4,"nbformat_minor":0}